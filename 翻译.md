# 近看效果更好:递归注意卷积神经网络用于细粒度图像识别

## 摘要

​	利用计算机视觉技术进行细粒度分类(如鸟类分类[2,34]、花卉分类[21,24]、汽车模型分类[14,19]等)已引起广泛关注。这个任务非常具有挑战性，因为一些细粒度的类别(例如“eared grebe”和“horned grebe”)只能由领域专家识别。与一般的识别不同，细粒度图像识别应该能够在从属类别中定位并表现出非常边缘的视觉差异，从而能够应用于广泛的应用，如专家级图像识别[15,31]、丰富的图像字幕[1,12]等。

## 介绍

![](D:\repositories\boke\pic\1.png)

​	图1所示。两种啄木鸟。我们可以从高度局部区域(例如，黄色方框中的头)观察到非常细微的视觉差异，这是很难从原始图像尺度中学习的。然而，如果我们能学会以更精细的尺度放大参与区域，这种差异就会更加生动和显著。[彩色效果最佳]

​	细粒度识别的挑战主要有两方面:**区分区域定位**和**从这些区域学习细粒度特征**。先前的研究已经取得了令人瞩目的进展通过引入partbased识别框架,通常包括两个步骤:1)**识别可能的对象区域通过分析卷积神经网络的反应一种无监督的方式或通过使用监督边界框/注释部分,2)从每个区域中提取区别的特征和编码成紧凑的向量识别**。虽然已经报告了一些有希望的结果，但进一步的改进还存在以下局限性。首先，***人类定义的区域或现有的无监督方法学习的区域可能不是机器分类[35]的最佳选择***。其次，***从类似的细粒度类别中发现的局部区域的细微视觉差异仍然很难学习***。我们发现区域检测和细粒度特征学习是相互关联的，可以相互促进。如图1所示，准确的头部定位可以促进识别性头部特征的学习，进一步帮助识别后脑中存在的不同颜色。为了解决上述问题，我们提出了一种新的递归注意卷积神经网络(RA-CNN)，用于无边界框/局部标注的细粒度识别。RA-CNN递归学习区分区域注意和基于区域的特征表示，相互增强。提出的RA-CNN是一种**叠加网络**，它将**完整图像的输入在多个尺度上转换成细粒度的局部区域**。首先，**多尺度网络具有相同的网络结构**，但在每个尺度上具有不同的参数，以适应不同分辨率的输入(如图1中的粗尺度和细尺度)。每个尺度上的学习由一个**分类子网络**和一个**注意力建议子网络(**APN)组成，可以确保在每个尺度上有足够的辨别能力，并为下一个细尺度生成准确的有值域。然后，用于**高分辨率区域的更精细的网络将放大的参与区域作为输入，以提取更细粒度的特征**。最后，该递归网络通过一个用于**分类的内尺度软最大损失和一个用于注意力建议网络的跨尺度两两排序损失来交替优化**。排名损失优化了更精细的网络，从而在正确的类别上产生比先前预测更高的信心分数。

​	由于更精细的网络可以**以一种周期性的方式**叠加，所以RA-CNN可以逐渐地从粗到细(例如，鸟类从身体到头部，然后到喙)关注最具辨别能力的区域。注意，准确的区域定位可以帮助识别基于区域的特征学习，反之亦然。因此，该网络可以**从区域定位和特征学习的相互增强中获益**。为了进一步利用集成学习的优势，通过学习全连通融合层，将多尺度特征深度融合到图像分类中。据我们所知，这项工作代表了首次尝试提出了一种用于细粒度识别的多尺度重复注意网络。我们的贡献可以总结如下:

1、 为了解决细粒度识别的挑战，我们提出了一种新的递归注意卷积神经网络结构，该结构能够以一种**相互增强的方式同时准确检测识别区域和有效地学习基于区域的表示**。

2、 我们提出一个两两排序的损失来优化注意力建议网络。与只有标签监督的区域定位器相比，这样的设计使得网络可以**参考以前的尺度**，逐步关注更细粒度的区域。

3、 我们对三个具有挑战性的数据集(幼鸟、斯坦福狗、斯坦福汽车)进行了全面的实验，并在所有这些数据集上取得了优于最先进方法的性能。

​	论文的其余部分组织如下。第二部分是对相关工作的回顾。第3节介绍了提出的方法。第4节给出了评价和分析，第5节给出了结论。

## 相关工作

​	细粒度图像识别的研究从两个维度展开，即**判别特征学习**(discriminative feature learning)和**精密区域定位**(sophisticated part localization)。

### 判别特征学习

​	学习判别特征是细粒度图像识别的关键。由于deep learning的成功，大部分的方法都依赖于强大的convolutional deep features，它在general和fine- categories上都比hand- made features有了显著的改善[4,5,6,17,29]。为了学习更强的特征表示，深度残差网络[9]通过优化残差函数将CNN扩展到152层，将ImageNet测试集[17]的错误率降低到3.75%。为了更好地模拟细粒度类别中存在的细微差异，最近提出了一种双线性结构[19]来计算**两个独立CNNs的两两特征交互来捕获图像的局部差异**，这在鸟类分类[30]中取得了最先进的结果。此外，[34]还提出了一种将CNN与Fisher向量[23]进行空间加权表示相结合的方法，该方法在鸟类[30]和犬类[13]数据集上都取得了较好的结果。

### 复杂的部分本地化

​	以前的工作主要侧重于利用边界框的额外注释和局部注释来定位细粒度识别中的重要区域[10、18、22、30、32、33]。然而，手工注释的大量参与使得这项任务对于大规模的实际问题不太实际。最近出现了一些针对更一般情况的工作，并**建议使用非监督的方法来提高区域的注意力**。基于视觉注意力的方法提出了一个**两层**的网络，在对象和部件上，部件模板（APN）通过聚类方案从CNN[31]的内部隐藏表示中学习。选择深度过滤器响应[34]和多粒度描述符[28]建议通过分析来自CNN的过滤器响应来学习一组部分检测器，这些过滤器响应以**非监督的方式**一致地响应特定的模式。空间变压器[11]更进一步，提出了一种动态机制，可以主动地对图像进行空间变换，以实现更精确的分类。然而，现有的模型由于体积小，难以准确地定位精细区域。与我们最相关的作品来自[20]和[35]。这两种方法都提出了放大区分的局部区域来提高细粒度识别的性能。然而，从[20]和[35]中学习区域本地化者**要么依赖于预处理的区域建议，要么依赖于类别标签**，这对准确的区域本地化提出了挑战。

![](D:\repositories\boke\pic\2.png)

​	图2。递归注意卷积神经网络(RA-CNN)的框架。输入从粗糙的全尺寸图像到更精细的区域注意(从上到下)。不同的网络模块分类(蓝色)和注意力的建议(用红色标识)被分类损失之间的拼箱标签或者优化预测Y (s)（预测值）和地面真理Y∗（标签值）在每个规模,和两两之间的排名损失Lrank pt^(s) 和pt ^(s + 1)从邻近的尺度,pt^(s) t和pt^(s + 1)表示的概率正确的类别,规模和s表示。APN是注意力建议网络，fc表示全连接层，softmax层通过fc层匹配类别条目，然后进行softmax操作。  +表示“裁剪”和“放大”操作。[彩色效果最佳]

## 方法

​	在本节中，我们将介绍用于细粒度图像识别的递归注意卷积神经网络(RA-CNN)。我们以图2中的具有三个刻度的网络为例，可以用类似的方式堆叠更精细的刻度。从a1的全尺寸图像到a2和a3的细粒度识别区域，输入是重复的，其中a2和a3分别将输入作为a1和a2的参与区域。首先，将不同尺度的图像输入卷积层(b1到b3)，提取基于区域的特征表示;其次，网络通过全连通和软最大层(c1到c3)来预测概率分数，通过注意力建议网络(d1, d2)来预测区域注意力。提出的RA-CNN通过交替学习每个尺度上的softmax分类损失和相邻尺度上的成对排序损失来优化收敛

### APN

​	多任务提法:传统的基于部分的细粒度识别框架没有利用经过深度训练的网络来**相互促进**本地化和识别的学习。摘要在区域建议网络(RPN)[8]最近成功的启发下，我们提出了一种注意建议网络(APN)，**该网络中区域注意的计算几乎是免费的**，并且可以端到端的训练。给定一个输入图像X，我们首先通过将图像输入到**预先训练好的卷积层中来提取基于区域的深度特征**。被提取的深度表示被表示为Wc*X，其中\*显示出的是一组卷积、池化和激活的操作，Wc显示出总的参数。我们进一步在每个尺度上将网络建模为具有两个输出的多任务公式。第一个任务被设计成**在细粒度类别上生成概率分布p**，如下图所示:
$$
p(X) = f(W_c*X)
$$
其中f()表示全连通层，将卷积特征映射到可与类别项匹配的特征向量上，并包含一个softmax层，进一步将特征向量转换为概率。第二个任务是**预测一个参与区域的一组框坐标，以获得下一个更精细的尺度**。将参与区域近似为三个参数的正方形，表示为:
$$
[t_x,t_y,t_l] = g(W_c*X)
$$
其中**tx、ty分别表示以x、y轴表示的正方形中心坐标，tl表示正方形边长的一半**。g()的具体形式可以用**三个输出的两层叠加的全连接层**来表示，这三个输出是参与区域的参数。值得注意的是，与基于地面真值盒强监督的区域建议网络相比，由于局部级标注往往难以获得，所以所提出的APN的学习是以弱监督的方式进行训练的。具体的学习过程和损失函数将在第3.2节中介绍。